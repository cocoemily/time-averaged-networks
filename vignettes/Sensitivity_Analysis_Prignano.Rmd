---
title: "Sensitivity Analysis"
author: "Andrew Gillreath-Brown"
date: "4/21/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(igraph)
library(ggraph)
library(purrr)
library(stringr)
library(DT)
library(ggpubr)
library(gridExtra)
# library(statnet)
# library(tnet)
# library(intergraph)

```

# Sensitivity Analysis
Here, we run a variety of sensitivity analyses on the original and time-averaged networks. This code has been adapted from Peeples, Matthew A. 2017. Network Science and Statistical Techniques for Dealing with Uncertainties in Archaeological Datasets. [online]. Available: [www.mattpeeples.net/netstats.html](http://www.mattpeeples.net/netstats.html). One main difference is that we use `igraph` rather than the `sna` and `network` packages.

## Load and prepare data for sensitivity analysis.

```{r load_data}

# First, load in all of the the igraph objects. However, we will only use Prignano_ta_graphs, as the first network for each time period will be the original graph.
load("../Data/Prignano_graph_objects.RData")

# The lists are unnested for 1 level.
Prignano.nets <- Prignano_ta_graphs[[1]]

# Give names to each list for each time period to keep track.
Prignano.names <- c("EIA1E", "EIA1L", "EIA2", "OA", "AA")
names(Prignano.nets) <- Prignano.names

prignano.names.full <- 
c("EIA1E_network_1", "EIA1E_network_2", "EIA1E_network_3", "EIA1E_network_4", 
"EIA1E_network_5", "EIA1L_network_1", "EIA1L_network_2a", "EIA1L_network_2b", 
"EIA1L_network_3a", "EIA1L_network_3b", "EIA1L_network_4a", "EIA1L_network_4b", 
"EIA1L_network_5", "EIA2_network_1", "EIA2_network_2a", "EIA2_network_2b", 
"EIA2_network_3a", "EIA2_network_3b", "EIA2_network_3c", "EIA2_network_4a", 
"EIA2_network_4b", "EIA2_network_5", "OA_network_1", "OA_network_2a", 
"OA_network_2b", "OA_network_3a", "OA_network_3b", "OA_network_4a", 
"OA_network_4b", "OA_network_5", "AA_network_1", "AA_network_2", 
"AA_network_3", "AA_network_4", "AA_network_5")

```

## Functions to get multiple centrality scores for binary networks.
```{r centrality, echo=FALSE}

# Calculate centrality scores for binary networks for igraph objects.
net.stats <- function(y) {
    # Calculate degree centrality
    dg <- as.matrix(igraph::degree(y))
    # Calculate eigenvector centrality
    eg <- as.matrix(igraph::evcent(y)$vector)
    # Calculate betweenness centrality
    bw <- igraph::betweenness(y, normalized = TRUE, directed = FALSE)
    # Combine centrality scores into matrix
    output <- cbind(dg, eg, bw)
    colnames(output) <- c("dg", "eg", "bw")
    return(output)
}  # return results of this function

net.stats.single <- function(y) {
    # Calculate clustering coefficient
    cc <- igraph::transitivity(y, "global")
    # Calculate modularity
    wtc = igraph::cluster_walktrap(y)
    mod <- igraph::modularity(as.undirected(y), membership(wtc))
    # Combine centrality scores into matrix
    output <- cbind(cc, mod)
    colnames(output) <- c("cc", "mod")
    return(output)
}  # return results of this function

```

## Functions for creating outputs
```{r output_functions, echo = FALSE, warning=F, message=F}

# Create output table for sensitivity analysis.
create_output_tables = function(BR.list) {
  dg.df = data.frame()
  eg.df = data.frame()
  bt.df = data.frame()
  cc.df = data.frame()
  mod.df = data.frame()
  
  for (n in Prignano.names) {
    for (ta in 1:length(BR.list[n][[1]])) {
      dg = as.data.frame(BR.list[n][[1]][[ta]][[1]]) %>%
        tidyr::gather(
          "S90",
          "S80",
          "S70",
          "S60",
          "S50",
          "S40",
          "S30",
          "S20",
          "S10",
          key = sample.perc,
          value = dg.rho
        ) %>%
        dplyr::mutate(sample.perc = as.numeric(str_sub(
          sample.perc,
          start = 2,
          end = length(sample.perc)
        ))) %>%
        dplyr::arrange(sample.perc) %>%
        dplyr::mutate(num.net = ta) %>%
        dplyr::mutate(orig.net = n)
      dg.df = rbind(dg.df, dg)
      
      eg = as.data.frame(BR.list[n][[1]][[ta]][[2]]) %>%
        tidyr::gather(
          "S90",
          "S80",
          "S70",
          "S60",
          "S50",
          "S40",
          "S30",
          "S20",
          "S10",
          key = sample.perc,
          value = eg.rho
        ) %>%
        dplyr::mutate(sample.perc = as.numeric(str_sub(
          sample.perc,
          start = 2,
          end = length(sample.perc)
        ))) %>%
        dplyr::arrange(sample.perc) %>%
        dplyr::mutate(num.net = ta) %>%
        dplyr::mutate(orig.net = n)
      eg.df = rbind(eg.df, eg)
      
      bt = as.data.frame(BR.list[n][[1]][[ta]][[3]]) %>%
        tidyr::gather(
          "S90",
          "S80",
          "S70",
          "S60",
          "S50",
          "S40",
          "S30",
          "S20",
          "S10",
          key = sample.perc,
          value = bt.rho
        ) %>%
        dplyr::mutate(sample.perc = as.numeric(str_sub(
          sample.perc,
          start = 2,
          end = length(sample.perc)
        ))) %>%
        dplyr::arrange(sample.perc) %>%
        dplyr::mutate(num.net = ta) %>%
        dplyr::mutate(orig.net = n)
      bt.df = rbind(bt.df, bt)
      
      cc = as.data.frame(BR.list[n][[1]][[ta]][[4]]) %>%
        tidyr::gather(
          "S100",
          "S90",
          "S80",
          "S70",
          "S60",
          "S50",
          "S40",
          "S30",
          "S20",
          "S10",
          key = sample.perc,
          value = cc.val
        ) %>%
        dplyr::mutate(sample.perc = as.numeric(str_sub(
          sample.perc,
          start = 2,
          end = length(sample.perc)
        ))) %>%
        dplyr::arrange(sample.perc) %>%
        dplyr::mutate(num.net = ta) %>%
        dplyr::mutate(orig.net = n)
      cc.df = rbind(cc.df, cc)
      
      mod = as.data.frame(BR.list[n][[1]][[ta]][[5]]) %>%
        tidyr::gather(
          "S100",
          "S90",
          "S80",
          "S70",
          "S60",
          "S50",
          "S40",
          "S30",
          "S20",
          "S10",
          key = sample.perc,
          value = mod.val
        ) %>%
        dplyr::mutate(sample.perc = as.numeric(str_sub(
          sample.perc,
          start = 2,
          end = length(sample.perc)
        ))) %>%
        dplyr::arrange(sample.perc) %>%
        dplyr::mutate(num.net = ta) %>%
        dplyr::mutate(orig.net = n)
      mod.df = rbind(mod.df, mod)
    }
  }
  
  output.dg = dg.df %>% group_by(orig.net, num.net, sample.perc) %>%
    summarize(
      min = min(dg.rho, na.rm = TRUE),
      quart.1 = quantile(dg.rho, probs = 0.25, na.rm = TRUE),
      med = median(dg.rho, na.rm = TRUE),
      quart.3 = quantile(dg.rho, probs = 0.75, na.rm = TRUE),
      max = max(dg.rho, na.rm = TRUE)
    ) %>%
    dplyr::mutate(orig.net = factor(orig.net, levels = Prignano.names)) %>%
    dplyr::arrange(orig.net)
  
  output.eg = eg.df %>% group_by(orig.net, num.net, sample.perc) %>%
    summarize(
      min = min(eg.rho, na.rm = TRUE),
      quart.1 = quantile(eg.rho, probs = 0.25, na.rm = TRUE),
      med = median(eg.rho, na.rm = TRUE),
      quart.3 = quantile(eg.rho, probs = 0.75, na.rm = TRUE),
      max = max(eg.rho, na.rm = TRUE)
    ) %>%
    dplyr::mutate(orig.net = factor(orig.net, levels = Prignano.names)) %>%
    dplyr::arrange(orig.net)
  
  output.bt = bt.df %>% group_by(orig.net, num.net, sample.perc) %>%
    summarize(
      min = min(bt.rho, na.rm = TRUE),
      quart.1 = quantile(bt.rho, probs = 0.25, na.rm = TRUE),
      med = median(bt.rho, na.rm = TRUE),
      quart.3 = quantile(bt.rho, probs = 0.75, na.rm = TRUE),
      max = max(bt.rho, na.rm = TRUE)
    ) %>%
    dplyr::mutate(orig.net = factor(orig.net, levels = Prignano.names)) %>%
    dplyr::arrange(orig.net)
  
  output.cc = cc.df %>% group_by(orig.net, num.net, sample.perc) %>%
    summarize(
      min = min(cc.val, na.rm = TRUE),
      quart.1 = quantile(cc.val, probs = 0.25, na.rm = TRUE),
      med = median(cc.val, na.rm = TRUE),
      quart.3 = quantile(cc.val, probs = 0.75, na.rm = TRUE),
      max = max(cc.val, na.rm = TRUE)
    ) %>%
    dplyr::mutate(orig.net = factor(orig.net, levels = Prignano.names)) %>%
    dplyr::arrange(orig.net)
  
  output.mod = mod.df %>% group_by(orig.net, num.net, sample.perc) %>%
    summarize(
      min = min(mod.val, na.rm = TRUE),
      quart.1 = quantile(mod.val, probs = 0.25, na.rm = TRUE),
      med = median(mod.val, na.rm = TRUE),
      quart.3 = quantile(mod.val, probs = 0.75, na.rm = TRUE),
      max = max(mod.val, na.rm = TRUE)
    ) %>%
    dplyr::mutate(orig.net = factor(orig.net, levels = Prignano.names)) %>%
    dplyr::arrange(orig.net)
  
  return(list(output.dg, output.eg, output.bt, output.cc, output.mod))
}

```

## Function for creating plots
```{r plot_function, echo = FALSE, warning=F, message=F}

plot_sa <- function(sa.data) {
  # Prepare data for plotting.
  dg.mat <- as.data.frame(sa.data[[1]]) %>%
    tidyr::gather(s.fraction, values)
  ev.mat <- as.data.frame(sa.data[[2]]) %>%
    tidyr::gather(s.fraction, values)
  bw.mat <- as.data.frame(sa.data[[3]]) %>%
    tidyr::gather(s.fraction, values)
  
  cc.mat.long <- as.data.frame(sa.data[[4]]) %>%
    tidyr::gather(
      "S100",
      "S90",
      "S80",
      "S70",
      "S60",
      "S50",
      "S40",
      "S30",
      "S20",
      "S10",
      key = sample.perc,
      value = cc.score
    )
  
  mod.mat.long <- as.data.frame(sa.data[[5]]) %>%
    tidyr::gather(
      "S100",
      "S90",
      "S80",
      "S70",
      "S60",
      "S50",
      "S40",
      "S30",
      "S20",
      "S10",
      key = sample.perc,
      value = mod.score
    )
  
  # Save individual plots, then can create an arranged plot, so that each network has 1 set of figures.
  dg.mat.plot <- ggpubr::ggboxplot(
    dg.mat,
    title = "Degree Centrality",
    x = "s.fraction",
    y = "values",
    xlab = "Sampling Fraction",
    ylab = "Spearman's Rho",
    bxp.errorbar = TRUE
  ) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_classic()
  
  ev.mat.plot <- ggpubr::ggboxplot(
    ev.mat,
    title = "Eigenvector Centrality",
    x = "s.fraction",
    y = "values",
    xlab = "Sampling Fraction",
    ylab = "Spearman's Rho",
    bxp.errorbar = TRUE
  ) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_classic()
  
  bw.mat.plot <- ggpubr::ggboxplot(
    bw.mat,
    title = "Betweenness Centrality",
    x = "s.fraction",
    y = "values",
    xlab = "Sampling Fraction",
    ylab = "Spearman's Rho",
    bxp.errorbar = TRUE
  ) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_classic()
  
  cc.mat.long.plot <- ggpubr::ggline(
    cc.mat.long,
    title = "Clustering Coefficient",
    x = "sample.perc",
    y = "cc.score",
    xlab = "Sampling Fraction",
    ylab = "Clustering Coefficient Value"
  ) +
    theme(plot.title = element_text(hjust = 0.5)) +
    theme_classic(base_size = 9)
  
  mod.mat.long.plot <- ggpubr::ggline(
    mod.mat.long,
    title = "Modularity",
    x = "sample.perc",
    y = "mod.score",
    xlab = "Sampling Fraction",
    ylab = "Modularity Value"
  ) +
    theme_classic()
  
  
    plot <- ggpubr::ggarrange(
      dg.mat.plot,
      ev.mat.plot,
      bw.mat.plot,
      cc.mat.long.plot,
      mod.mat.long.plot,
      labels = c("A", "B", "C", "D", "E"),
      ncol = 2,
      nrow = 3
    )
    
    return(plot)
  
}

```


## Potential Impact of Missing Nodes

### Over multiple centrality measures and/or networks

```{r missing_nodes_multiple, echo=FALSE, warning=FALSE}

# Set number of replicates.
nsim <- 750
samp.frac <-
  c("S90", "S80", "S70", "S60", "S50", "S40", "S30", "S20", "S10")

# Create a function that calculates correlations between the original and sub-sampled replicates from 90% to 10% for all three of the primary measures of centrality and clustering coefficient and modularity using the format from the net.stats and net.stats.single function to assess the rank order correlation of nodes.
cv.resamp.bin <- function(x) {
  # Calculate all network stats for the original network.
  stats.g <- net.stats(x)
  stats.g.single <- net.stats.single(x)
  mat <- as.matrix(igraph::get.adjacency(x))
  # Count number of rows (nodes).
  dim.x <- dim(mat)[1]
  # Define empty matrices for output.
  dg.mat <- matrix(NA, nsim, 9)
  ev.mat <- matrix(NA, nsim, 9)
  bw.mat <- matrix(NA, nsim, 9)
  cc.mat <- matrix(NA, 1, 9)
  mod.mat <- matrix(NA, 1, 9)
  # Add column names based on sampling fraction.
  colnames(dg.mat) <- samp.frac
  colnames(ev.mat) <- samp.frac
  colnames(bw.mat) <- samp.frac
  colnames(cc.mat) <- samp.frac
  colnames(mod.mat) <- samp.frac
  
  # This double loop goes through each sampling fraction and each random replicate to calculate centrality statistics and runs a Spearman's Rho correlation between the resulting centrality values and the original sample. However, for clustering coefficient and modularity, these will just output the values from the different networks.
  for (j in 1:9) {
    for (i in 1:nsim) {
      sub.samp <-
        sample(seq(1, dim.x),
               size = round(dim.x * ((10 - j) / 10),
                            0),
               replace = F)
      temp.stats <-
        net.stats(igraph::graph_from_adjacency_matrix(mat[sub.samp, sub.samp]))
      temp.stats.single <-
        net.stats.single(igraph::graph_from_adjacency_matrix(mat[sub.samp, sub.samp]))
      dg.mat[i, j] <-
        suppressWarnings(cor(temp.stats[, 1], stats.g[sub.samp,
                                                      1], method = "spearman"))
      ev.mat[i, j] <-
        suppressWarnings(cor(temp.stats[, 2], stats.g[sub.samp,
                                                      2], method = "spearman"))
      bw.mat[i, j] <-
        suppressWarnings(cor(temp.stats[, 3], stats.g[sub.samp,
                                                      3], method = "spearman"))
      cc.mat[1, j] <- temp.stats.single[, 1]
      mod.mat[1, j] <- temp.stats.single[, 2]
    }
  }
  # Add original to cc.mat and mod.mat (i.e,. 100% sampling).
  cc.mat <- as.data.frame(cc.mat) %>%
    dplyr::mutate(S100 = stats.g.single[1]) %>%
    dplyr::select(S100, everything()) %>%
    as.matrix()
  mod.mat <- as.data.frame(mod.mat) %>%
    dplyr::mutate(S100 = stats.g.single[2]) %>%
    dplyr::select(S100, everything()) %>%
    as.matrix()
  # Create list for output and populate it.
  out.list <- list()
  out.list[[1]] <- dg.mat
  out.list[[2]] <- ev.mat
  out.list[[3]] <- bw.mat
  out.list[[4]] <- cc.mat
  out.list[[5]] <- mod.mat
  
  return(out.list)
}  # return the resulting list


# Now apply the function to all 35 networks for Prignano.
BR.rs <- Prignano.nets %>%
  purrr::map(~ purrr::map(.x, cv.resamp.bin))


# Create output tables for node removal sensitivity analysis
outputs.rs = create_output_tables(BR.rs)
# knitr::kable(outputs.rs[[1]], caption = "Degree Centrality Rho Values")
# knitr::kable(outputs.rs[[2]], caption = "Eigenvector Centrality Rho Values")
# knitr::kable(output.rs[[3]], caption = "Betweenness Centrality Rho Values")
# knitr::kable(output.rs[[4]], caption = "Clustering Coefficient Values")
# knitr::kable(output.rs[[5]], caption = "Modularity Values")
datatable(
  outputs.rs[[1]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Degree Centrality Rho Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)
datatable(
  outputs.rs[[2]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Eigenvector Centrality Rho Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)
datatable(
  outputs.rs[[3]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Betweenness Centrality Rho Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)
datatable(
  outputs.rs[[4]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Clustering Coefficient Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)
datatable(
  outputs.rs[[5]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Modularity Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)


# Plotting
# First, all the networks are unlisted. The final result is that there is the network, then the order of the time averaged networks.
BR.rs.plotting <- unlist(BR.rs, recursive = FALSE)

# This outputs a list of ggplot objects for all the time averaged networks for Prignano, using the plot_sa function.
plots_sa_nodes <- BR.rs.plotting %>%
  purrr::map(plot_sa)

# Then, we can rename each plot to have its network number and number of graphs (e.g., EIA1E_network_1).
names(plots_sa_nodes) <- c(prignano.names.full)

# Arrange each ggplot object to be 1 per page. Use marrangeGrob so that can save each ggplot object to each page, and also put name at top of page.
ml.nodes <- gridExtra::marrangeGrob(plots_sa_nodes, nrow=1, ncol=1, top=quote(names(plots_sa_nodes)[g]))

# Save as one pdf. Use scale here in order for the multi-plots to fit on each page.
ggsave("figures/sensitivity-analysis/Prignano/sensitivity.nodes.plots.prignano.pdf", ml.nodes, scale = 1.5)
plot(ml.nodes)

```


## Potential impact of missing edges
```{r missing_edges, echo=FALSE, warning=F, message=F}

# Set number of replicates.
nsim <- 750
samp.frac <-
  c("S90", "S80", "S70", "S60", "S50", "S40", "S30", "S20", "S10")

# Create a function that calculates correlations between the original and sub-sampled replicates from 90% to 10% for all three of the primary measures of centrality and clustering coefficient and modularity using the format from the net.stats and net.stats.single function to assess the rank order correlation of nodes.
cv.resamp.edge <- function(x) {
  stats.g <- net.stats(x)
  stats.g.single <- net.stats.single(x)
  mat <- as.matrix(igraph::get.adjacency(x))
  dim.x <- dim(mat)[1]
  dg.mat <- matrix(NA, nsim, 9)
  ev.mat <- matrix(NA, nsim, 9)
  bw.mat <- matrix(NA, nsim, 9)
  cc.mat <- matrix(NA, 1, 9)
  mod.mat <- matrix(NA, 1, 9)
  colnames(dg.mat) <- samp.frac
  colnames(ev.mat) <- samp.frac
  colnames(bw.mat) <- samp.frac
  colnames(cc.mat) <- samp.frac
  colnames(mod.mat) <- samp.frac
  
  for (j in 1:9) {
    for (i in 1:nsim) {
      sub.samp <-
        sample(
          seq(1, igraph::gsize(x)),
          size = round(igraph::gsize(x) *
                         (j / 10), 0),
          replace = F
        )
      temp.net <- x
      net.reduced <- igraph::delete.edges(temp.net, sub.samp)
      temp.stats <- net.stats(net.reduced)
      temp.stats.single <- net.stats.single(net.reduced)
      dg.mat[i, j] <-
        cor(temp.stats[, 1], stats.g[, 1], method = "spearman")
      ev.mat[i, j] <-
        cor(temp.stats[, 2], stats.g[, 2], method = "spearman")
      bw.mat[i, j] <-
        cor(temp.stats[, 3], stats.g[, 3], method = "spearman")
      cc.mat[1, j] <- temp.stats.single[, 1]
      mod.mat[1, j] <- temp.stats.single[, 2]
      
    }
  }
  # Add original to cc.mat and mod.mat (i.e., 100% sampling).
  cc.mat <- as.data.frame(cc.mat) %>%
    dplyr::mutate(S100 = stats.g.single[1]) %>%
    dplyr::select(S100, everything()) %>%
    as.matrix()
  mod.mat <- as.data.frame(mod.mat) %>%
    dplyr::mutate(S100 = stats.g.single[2]) %>%
    dplyr::select(S100, everything()) %>%
    as.matrix()
  
  out.list <- list()
  out.list[[1]] <- dg.mat
  out.list[[2]] <- ev.mat
  out.list[[3]] <- bw.mat
  out.list[[4]] <- cc.mat
  out.list[[5]] <- mod.mat
  return(out.list)
}

# Now apply the function to all 35 networks for Prignano.
BR.edge <- Prignano.nets %>%
  purrr::map(~ purrr::map(.x, cv.resamp.edge))


# Create output tables for node removal sensitivity analysis.
outputs.edge = create_output_tables(BR.edge)
# knitr::kable(outputs.edge[[1]], caption = "Degree Centrality Rho Values")
# knitr::kable(outputs.edge[[2]], caption = "Eigenvector Centrality Rho Values")
# knitr::kable(output.edge[[3]], caption = "Betweenness Centrality Rho Values")
# knitr::kable(output.edge[[4]], caption = "Clustering Coefficient Values")
# knitr::kable(output.edge[[5]], caption = "Modularity Values")
datatable(
  outputs.edge[[1]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Degree Centrality Rho Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)
datatable(
  outputs.edge[[2]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Eigenvector Centrality Rho Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)
datatable(
  outputs.edge[[3]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Betweenness Centrality Rho Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)
datatable(
  outputs.edge[[4]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Clustering Coefficient Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)
datatable(
  outputs.edge[[5]],
  extensions = 'Buttons',
  options = list(dom = 'Bfrtip', buttons = c('copy', 'csv')),
  caption = "Modularity Values",
  rownames = FALSE,
  colnames = c(
    "Original Network",
    "Number of Networks Averaged",
    "Sample Percentage",
    "Min",
    "1st Quartile",
    "Median",
    "3rd Quartile",
    "Max"
  )
) %>%
  formatRound(c("min", "quart.1", "med", "quart.3", "max"), 3)


# Plotting
# First, all the networks are unlisted. The final result is that there is the network, then the order of the time averaged networks.
BR.edge.plotting <- unlist(BR.edge, recursive = FALSE)

# This outputs a list of ggplot objects for all the time averaged networks for Prignano, using the plot_sa function.
plots_sa_edges <- BR.edge.plotting %>%
  purrr::map(plot_sa)

# Then, we can rename each plot to have its network number and number of graphs (e.g., EIA1E_network_1).
names(plots_sa_edges) <- c(prignano.names.full)

# Arrange each ggplot object to be 1 per page. Use marrangeGrob so that can save each ggplot object to each page, and also put name at top of page.
ml.edges <- gridExtra::marrangeGrob(plots_sa_edges, nrow=1, ncol=1, top=quote(names(plots_sa_edges)[g]))

# Save as one pdf. Use scale here in order for the multi-plots to fit on each page.
ggsave("figures/sensitivity-analysis/Prignano/sensitivity.edges.plots.prignano.pdf", ml.edges, scale = 1.5)
plot(ml.edges)

```
